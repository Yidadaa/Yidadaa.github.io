<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>经典统计学习方法——决策树(ID3/C4.5/CART) | YiFei Zhang&#39;s Blog</title>
    <meta name="description" content="在这里了解我的一切，对编程的热爱永不停歇。">
    <meta name="generator" content="VuePress 1.3.0">
    <link rel="stylesheet" href="https://cdn.bootcss.com/prism/9000.0.1/themes/prism.min.css">
  <link rel="stylesheet" href="https://cdn.bootcss.com/KaTeX/0.5.1/katex.min.css">
  <link rel="icon" type="image/png" href="/favicons/icon.png">
    
    <link rel="preload" href="/assets/css/0.styles.e2e8ac01.css" as="style"><link rel="preload" href="/assets/js/app.93183d9f.js" as="script"><link rel="preload" href="/assets/js/11.0d225d36.js" as="script"><link rel="preload" href="/assets/js/7.8a22378a.js" as="script"><link rel="preload" href="/assets/js/2.e0bd73be.js" as="script"><link rel="preload" href="/assets/js/26.f59e5e8d.js" as="script"><link rel="preload" href="/assets/js/6.5014c355.js" as="script"><link rel="prefetch" href="/assets/js/10.3fd41b4c.js"><link rel="prefetch" href="/assets/js/12.35beec42.js"><link rel="prefetch" href="/assets/js/13.e9f7972d.js"><link rel="prefetch" href="/assets/js/14.d45a7715.js"><link rel="prefetch" href="/assets/js/15.442e7d18.js"><link rel="prefetch" href="/assets/js/16.1b3d6946.js"><link rel="prefetch" href="/assets/js/17.456ba042.js"><link rel="prefetch" href="/assets/js/18.a350911e.js"><link rel="prefetch" href="/assets/js/19.3bcafa5a.js"><link rel="prefetch" href="/assets/js/20.550d1cd3.js"><link rel="prefetch" href="/assets/js/21.7292ce47.js"><link rel="prefetch" href="/assets/js/22.aa9b0fc4.js"><link rel="prefetch" href="/assets/js/23.b93d004e.js"><link rel="prefetch" href="/assets/js/24.6137bd71.js"><link rel="prefetch" href="/assets/js/25.7352d0b9.js"><link rel="prefetch" href="/assets/js/27.f1ef900c.js"><link rel="prefetch" href="/assets/js/28.63255274.js"><link rel="prefetch" href="/assets/js/29.d39cd055.js"><link rel="prefetch" href="/assets/js/3.eda7a40c.js"><link rel="prefetch" href="/assets/js/30.d0f0a586.js"><link rel="prefetch" href="/assets/js/31.bde49974.js"><link rel="prefetch" href="/assets/js/32.de6c6cb5.js"><link rel="prefetch" href="/assets/js/4.bd24dc8d.js"><link rel="prefetch" href="/assets/js/5.6768c2d6.js"><link rel="prefetch" href="/assets/js/8.43e59a10.js"><link rel="prefetch" href="/assets/js/9.36ffbd03.js">
    <link rel="stylesheet" href="/assets/css/0.styles.e2e8ac01.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div><div class="header-wrap" data-v-4996346c><div class="header page" data-v-4996346c><div class="left" data-v-4996346c><div class="motto" data-v-4996346c></div> <div class="nav" data-v-4996346c></div></div> <div class="right" data-v-4996346c><div class="search-box" data-v-4996346c><input aria-label="Search" placeholder="" autocomplete="off" spellcheck="false" value=""> <!----></div></div></div></div> <div class="page post-page"><div class="title"><div class="post-title">经典统计学习方法——决策树(ID3/C4.5/CART)</div></div> <div class="info"><div class="author">Yidadaa</div> <div class="date">2017/08/18</div></div> <div class="post-content"><div class="content__default"><h1 id="经典统计学习方法——决策树-id3-c4-5-cart"><a href="#经典统计学习方法——决策树-id3-c4-5-cart" class="header-anchor">#</a> 经典统计学习方法——决策树(ID3/C4.5/CART)</h1> <p>最近开始技术♂转型，开始搞机器学习，使用教材是李航老师的《统计学习方法》，基本涵盖了经典的机器学习方法，只不过缺少神经网络部分，准备看完这本书之后，继续学习 <a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener noreferrer">CS231n<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> 。</p> <p>前三章的内容都比较基础，第一章介绍了统计学习的基本要素以及基本步骤，第二、三章分别介绍了两种基础的模型：感知机和k近邻法，都比较简单，50行代码就能搞定。</p> <p>从第四章开始，本书的难度开始逐渐拔高，书中出现了越来越多的数学证明，第四章的朴素贝叶斯分类器中，用到了很多概率论的知识，比如极大似然估计、 贝叶斯估计等。如果要深入机器学习原理的话，还是要回归到线性代数和概率论的学习中。</p> <p>本文着重讲第五章的内容——决策树。</p> <h2 id="决策树简述"><a href="#决策树简述" class="header-anchor">#</a> 决策树简述</h2> <p>决策树是本书出现的第一种真正意义上的高可用方法，当然前一章的朴素贝叶斯分类器也算，但从复杂度熵来讲，决策树更胜一筹。</p> <p>决策树是一种基本的分类与回归方法，决策树的学习包括：特征选择、决策树的生成和决策树的修剪。其中特征选择决定了决策树的结构，决策树的生成和修剪阶段主要决定决策树的复杂度（深度）。</p> <h2 id="决策树的特征选择"><a href="#决策树的特征选择" class="header-anchor">#</a> 决策树的特征选择</h2> <p>决策树特征选择方式的不同，衍生出了不同的算法，比如ID3、C4.5、CART等。以这三种为例，其实ID3与C4.5只是特征选择函数不同，前者依照信息增益，后者依照信息增益比，生成的树的结构很相似，同时也使用相同的剪枝算法。CART较为特殊，后文将其分开来讲。</p> <h2 id="id3与c4-5算法"><a href="#id3与c4-5算法" class="header-anchor">#</a> ID3与C4.5算法</h2> <p>决策树生成过程中，通过计算不同特征的划分带来的信息增益，可以决定是否继续生成决策树。</p> <p>这两种算法生成的决策树，每一支子树都是一个特征值的可能值，使用时只需要按照标定的顺序，对输入变量各个特征值沿着树从根节点一直比对，延续到的叶节点就标定了该输入变量的最终分类。</p></div></div> <!----></div> <div class="footer" data-v-c51747ec><div class="footer-content page" data-v-c51747ec>
    Copyright 2020
  </div></div></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.93183d9f.js" defer></script><script src="/assets/js/11.0d225d36.js" defer></script><script src="/assets/js/7.8a22378a.js" defer></script><script src="/assets/js/2.e0bd73be.js" defer></script><script src="/assets/js/26.f59e5e8d.js" defer></script><script src="/assets/js/6.5014c355.js" defer></script>
  </body>
</html>
