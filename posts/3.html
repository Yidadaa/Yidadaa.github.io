<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>经典统计学习方法——决策树(ID3/C4.5/CART) | YiFei Zhang&#39;s Blog</title>
    <meta name="description" content="在这里了解我的一切，对编程的热爱永不停歇。">
    <meta name="generator" content="VuePress 1.3.0">
    <link rel="stylesheet" href="https://cdn.bootcss.com/prism/9000.0.1/themes/prism.min.css">
  <link rel="stylesheet" href="https://cdn.bootcss.com/KaTeX/0.5.1/katex.min.css">
  <link rel="icon" type="image/png" href="/favicons/icon.png">
    
    <link rel="preload" href="/assets/css/0.styles.a0fda9c7.css" as="style"><link rel="preload" href="/assets/js/app.98c20e97.js" as="script"><link rel="preload" href="/assets/js/12.7564357d.js" as="script"><link rel="preload" href="/assets/js/7.2b98330f.js" as="script"><link rel="preload" href="/assets/js/2.b7c0b55c.js" as="script"><link rel="preload" href="/assets/js/28.7dacb917.js" as="script"><link rel="preload" href="/assets/js/6.72135ada.js" as="script"><link rel="prefetch" href="/assets/js/10.eb39f85e.js"><link rel="prefetch" href="/assets/js/11.57fd9d89.js"><link rel="prefetch" href="/assets/js/13.9af6e9b2.js"><link rel="prefetch" href="/assets/js/14.db6268ad.js"><link rel="prefetch" href="/assets/js/15.da0dc55a.js"><link rel="prefetch" href="/assets/js/16.2d5ffbec.js"><link rel="prefetch" href="/assets/js/17.639b981e.js"><link rel="prefetch" href="/assets/js/18.728bff98.js"><link rel="prefetch" href="/assets/js/19.2739cfd3.js"><link rel="prefetch" href="/assets/js/20.6c67605d.js"><link rel="prefetch" href="/assets/js/21.7e8f9d8d.js"><link rel="prefetch" href="/assets/js/22.bd6a575c.js"><link rel="prefetch" href="/assets/js/23.9caa854b.js"><link rel="prefetch" href="/assets/js/24.19f984ff.js"><link rel="prefetch" href="/assets/js/25.13074256.js"><link rel="prefetch" href="/assets/js/26.cb0deb68.js"><link rel="prefetch" href="/assets/js/27.0efdadd4.js"><link rel="prefetch" href="/assets/js/29.fadb250a.js"><link rel="prefetch" href="/assets/js/3.3d15d864.js"><link rel="prefetch" href="/assets/js/30.9c9aa65d.js"><link rel="prefetch" href="/assets/js/31.c0835d50.js"><link rel="prefetch" href="/assets/js/32.a9088180.js"><link rel="prefetch" href="/assets/js/33.42bf1b2e.js"><link rel="prefetch" href="/assets/js/34.8bbdd14d.js"><link rel="prefetch" href="/assets/js/4.458a9fae.js"><link rel="prefetch" href="/assets/js/5.a1f54807.js"><link rel="prefetch" href="/assets/js/8.601360c2.js"><link rel="prefetch" href="/assets/js/9.023ae887.js">
    <link rel="stylesheet" href="/assets/css/0.styles.a0fda9c7.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div><div class="header-wrap" data-v-a542e14c><div class="header page" data-v-a542e14c><div class="left" data-v-a542e14c><div class="motto" data-v-a542e14c></div> <div class="nav" data-v-a542e14c></div></div> <div class="right" data-v-a542e14c><div class="search-box" data-v-a542e14c><input aria-label="Search" placeholder="" autocomplete="off" spellcheck="false" value=""> <!----></div></div></div></div> <div class="page post-page"><div class="title"><div class="post-title">经典统计学习方法——决策树(ID3/C4.5/CART)</div></div> <div class="info"><div class="author">Yidadaa</div> <div class="date">2017/08/18</div></div> <div class="post-content"><div class="content__default"><h1 id="经典统计学习方法——决策树-id3-c4-5-cart"><a href="#经典统计学习方法——决策树-id3-c4-5-cart" class="header-anchor">#</a> 经典统计学习方法——决策树(ID3/C4.5/CART)</h1> <p>最近开始技术♂转型，开始搞机器学习，使用教材是李航老师的《统计学习方法》，基本涵盖了经典的机器学习方法，只不过缺少神经网络部分，准备看完这本书之后，继续学习 <a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener noreferrer">CS231n<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> 。</p> <p>前三章的内容都比较基础，第一章介绍了统计学习的基本要素以及基本步骤，第二、三章分别介绍了两种基础的模型：感知机和k近邻法，都比较简单，50行代码就能搞定。</p> <p>从第四章开始，本书的难度开始逐渐拔高，书中出现了越来越多的数学证明，第四章的朴素贝叶斯分类器中，用到了很多概率论的知识，比如极大似然估计、 贝叶斯估计等。如果要深入机器学习原理的话，还是要回归到线性代数和概率论的学习中。</p> <p>本文着重讲第五章的内容——决策树。</p> <h2 id="决策树简述"><a href="#决策树简述" class="header-anchor">#</a> 决策树简述</h2> <p>决策树是本书出现的第一种真正意义上的高可用方法，当然前一章的朴素贝叶斯分类器也算，但从复杂度熵来讲，决策树更胜一筹。</p> <p>决策树是一种基本的分类与回归方法，决策树的学习包括：特征选择、决策树的生成和决策树的修剪。其中特征选择决定了决策树的结构，决策树的生成和修剪阶段主要决定决策树的复杂度（深度）。</p> <h2 id="决策树的特征选择"><a href="#决策树的特征选择" class="header-anchor">#</a> 决策树的特征选择</h2> <p>决策树特征选择方式的不同，衍生出了不同的算法，比如ID3、C4.5、CART等。以这三种为例，其实ID3与C4.5只是特征选择函数不同，前者依照信息增益，后者依照信息增益比，生成的树的结构很相似，同时也使用相同的剪枝算法。CART较为特殊，后文将其分开来讲。</p> <h2 id="id3与c4-5算法"><a href="#id3与c4-5算法" class="header-anchor">#</a> ID3与C4.5算法</h2> <p>决策树生成过程中，通过计算不同特征的划分带来的信息增益，可以决定是否继续生成决策树。</p> <p>这两种算法生成的决策树，每一支子树都是一个特征值的可能值，使用时只需要按照标定的顺序，对输入变量各个特征值沿着树从根节点一直比对，延续到的叶节点就标定了该输入变量的最终分类。</p></div></div> <!----></div> <div class="footer" data-v-87c5cddc><div class="footer-content page" data-v-87c5cddc><div class="footer-title power" data-v-87c5cddc>本博客驱动自</div> <a href="https://github.com/Yidadaa/Issue-Blog-With-Github-Action" class="logo" data-v-87c5cddc>ISSUE BLOG</a> <div class="footer-title" data-v-87c5cddc>友情链接</div> <div class="links" data-v-87c5cddc><a href="sssssss" class="link" data-v-87c5cddc>xxxxx</a><a href="sssssss" class="link" data-v-87c5cddc>xxxxx</a><a href="sssssss" class="link" data-v-87c5cddc>xxxxx</a><a href="sssssss" class="link" data-v-87c5cddc>xxxxx</a></div></div></div></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.98c20e97.js" defer></script><script src="/assets/js/12.7564357d.js" defer></script><script src="/assets/js/7.2b98330f.js" defer></script><script src="/assets/js/2.b7c0b55c.js" defer></script><script src="/assets/js/28.7dacb917.js" defer></script><script src="/assets/js/6.72135ada.js" defer></script>
  </body>
</html>
