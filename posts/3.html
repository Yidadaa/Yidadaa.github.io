<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>经典统计学习方法——决策树(ID3/C4.5/CART) | YiFei Zhang&#39;s Blog</title>
    <meta name="description" content="在这里了解我的一切，对编程的热爱永不停歇。">
    <meta name="generator" content="VuePress 1.3.0">
    <link rel="stylesheet" href="https://cdn.bootcss.com/prism/9000.0.1/themes/prism.min.css">
  <link rel="stylesheet" href="https://cdn.bootcss.com/KaTeX/0.5.1/katex.min.css">
  <link rel="icon" type="image/png" href="https://avatars2.githubusercontent.com/u/16968934?s=460&amp;v=4">
    
    <link rel="preload" href="/assets/css/0.styles.4b977857.css" as="style"><link rel="preload" href="/assets/js/app.8c029825.js" as="script"><link rel="preload" href="/assets/js/12.36e4d62b.js" as="script"><link rel="preload" href="/assets/js/8.63383f0d.js" as="script"><link rel="preload" href="/assets/js/3.92a88905.js" as="script"><link rel="preload" href="/assets/js/28.ce630df6.js" as="script"><link rel="preload" href="/assets/js/7.6caff623.js" as="script"><link rel="prefetch" href="/assets/js/10.c1e35cc7.js"><link rel="prefetch" href="/assets/js/11.10aef25e.js"><link rel="prefetch" href="/assets/js/13.1f0d1ec5.js"><link rel="prefetch" href="/assets/js/14.43e95bf4.js"><link rel="prefetch" href="/assets/js/15.a97cca82.js"><link rel="prefetch" href="/assets/js/16.3f59aad2.js"><link rel="prefetch" href="/assets/js/17.bf137d55.js"><link rel="prefetch" href="/assets/js/18.af46dc23.js"><link rel="prefetch" href="/assets/js/19.27964793.js"><link rel="prefetch" href="/assets/js/2.4ef930ff.js"><link rel="prefetch" href="/assets/js/20.29ebebf3.js"><link rel="prefetch" href="/assets/js/21.c7ca5ce1.js"><link rel="prefetch" href="/assets/js/22.3c3a5046.js"><link rel="prefetch" href="/assets/js/23.1540aa5b.js"><link rel="prefetch" href="/assets/js/24.8e8112a3.js"><link rel="prefetch" href="/assets/js/25.ccb2d937.js"><link rel="prefetch" href="/assets/js/26.e13a55c6.js"><link rel="prefetch" href="/assets/js/27.8b06f7a3.js"><link rel="prefetch" href="/assets/js/29.ff8f13ba.js"><link rel="prefetch" href="/assets/js/30.08591dbb.js"><link rel="prefetch" href="/assets/js/31.50c97bf2.js"><link rel="prefetch" href="/assets/js/32.8dd239bd.js"><link rel="prefetch" href="/assets/js/33.7690d82f.js"><link rel="prefetch" href="/assets/js/34.8bbdd14d.js"><link rel="prefetch" href="/assets/js/4.f670fc86.js"><link rel="prefetch" href="/assets/js/5.71c8e5ed.js"><link rel="prefetch" href="/assets/js/6.5cd503f0.js"><link rel="prefetch" href="/assets/js/9.0ae3e76e.js">
    <link rel="stylesheet" href="/assets/css/0.styles.4b977857.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div><div class="header-wrap" data-v-33920667><div class="header page" data-v-33920667><div class="left" data-v-33920667><div class="motto" data-v-33920667></div> <div class="nav" data-v-33920667></div></div> <div class="right" data-v-33920667><div class="search-box" data-v-33920667><input aria-label="Search" placeholder="" autocomplete="off" spellcheck="false" value=""> <!----></div></div></div></div> <div class="page post-page"><div class="title"><div class="post-title">经典统计学习方法——决策树(ID3/C4.5/CART)</div></div> <div class="info"><div class="author">Yidadaa</div> <div class="date">2017/08/18</div> <!----></div> <div class="post-content"><div class="content__default"><h1 id="经典统计学习方法——决策树-id3-c4-5-cart"><a href="#经典统计学习方法——决策树-id3-c4-5-cart" class="header-anchor">#</a> 经典统计学习方法——决策树(ID3/C4.5/CART)</h1> <p>最近开始技术♂转型，开始搞机器学习，使用教材是李航老师的《统计学习方法》，基本涵盖了经典的机器学习方法，只不过缺少神经网络部分，准备看完这本书之后，继续学习 <a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener noreferrer">CS231n<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> 。</p> <p>前三章的内容都比较基础，第一章介绍了统计学习的基本要素以及基本步骤，第二、三章分别介绍了两种基础的模型：感知机和k近邻法，都比较简单，50行代码就能搞定。</p> <p>从第四章开始，本书的难度开始逐渐拔高，书中出现了越来越多的数学证明，第四章的朴素贝叶斯分类器中，用到了很多概率论的知识，比如极大似然估计、 贝叶斯估计等。如果要深入机器学习原理的话，还是要回归到线性代数和概率论的学习中。</p> <p>本文着重讲第五章的内容——决策树。</p> <h2 id="决策树简述"><a href="#决策树简述" class="header-anchor">#</a> 决策树简述</h2> <p>决策树是本书出现的第一种真正意义上的高可用方法，当然前一章的朴素贝叶斯分类器也算，但从复杂度熵来讲，决策树更胜一筹。</p> <p>决策树是一种基本的分类与回归方法，决策树的学习包括：特征选择、决策树的生成和决策树的修剪。其中特征选择决定了决策树的结构，决策树的生成和修剪阶段主要决定决策树的复杂度（深度）。</p> <h2 id="决策树的特征选择"><a href="#决策树的特征选择" class="header-anchor">#</a> 决策树的特征选择</h2> <p>决策树特征选择方式的不同，衍生出了不同的算法，比如ID3、C4.5、CART等。以这三种为例，其实ID3与C4.5只是特征选择函数不同，前者依照信息增益，后者依照信息增益比，生成的树的结构很相似，同时也使用相同的剪枝算法。CART较为特殊，后文将其分开来讲。</p> <h2 id="id3与c4-5算法"><a href="#id3与c4-5算法" class="header-anchor">#</a> ID3与C4.5算法</h2> <p>决策树生成过程中，通过计算不同特征的划分带来的信息增益，可以决定是否继续生成决策树。</p> <p>这两种算法生成的决策树，每一支子树都是一个特征值的可能值，使用时只需要按照标定的顺序，对输入变量各个特征值沿着树从根节点一直比对，延续到的叶节点就标定了该输入变量的最终分类。</p></div></div> <!----></div> <div class="footer" data-v-a321e406><div class="footer-content page" data-v-a321e406><div class="left" data-v-a321e406><div class="footer-title" data-v-a321e406>Friend Links</div> <div class="links footer-text" data-v-a321e406></div>  <!----> <!----></div> <div class="right" data-v-a321e406><div class="footer-title power" data-v-a321e406>Powered by</div> <a href="https://github.com/Yidadaa/Issue-Blog-With-Github-Action" class="logo" data-v-a321e406>ISSUE BLOG</a></div></div></div></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.8c029825.js" defer></script><script src="/assets/js/12.36e4d62b.js" defer></script><script src="/assets/js/8.63383f0d.js" defer></script><script src="/assets/js/3.92a88905.js" defer></script><script src="/assets/js/28.ce630df6.js" defer></script><script src="/assets/js/7.6caff623.js" defer></script>
  </body>
</html>
