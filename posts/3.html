<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>经典统计学习方法——决策树(ID3/C4.5/CART) | YiFei Zhang&#39;s Blog</title>
    <meta name="description" content="在这里了解我的一切，对编程的热爱永不停歇。">
    <meta name="generator" content="VuePress 1.3.0">
    <link rel="stylesheet" href="https://cdn.bootcss.com/prism/9000.0.1/themes/prism.min.css">
  <link rel="stylesheet" href="https://cdn.bootcss.com/KaTeX/0.5.1/katex.min.css">
    
    <link rel="preload" href="/assets/css/0.styles.fa616454.css" as="style"><link rel="preload" href="/assets/js/app.d0804d39.js" as="script"><link rel="preload" href="/assets/js/8.2b72a042.js" as="script"><link rel="preload" href="/assets/js/6.7f8a78fa.js" as="script"><link rel="preload" href="/assets/js/22.7da8e57d.js" as="script"><link rel="preload" href="/assets/js/5.4dfe86e6.js" as="script"><link rel="prefetch" href="/assets/js/10.2aea81de.js"><link rel="prefetch" href="/assets/js/11.35118066.js"><link rel="prefetch" href="/assets/js/12.e2fdc2bb.js"><link rel="prefetch" href="/assets/js/13.0134257d.js"><link rel="prefetch" href="/assets/js/14.59104499.js"><link rel="prefetch" href="/assets/js/15.53ddc488.js"><link rel="prefetch" href="/assets/js/16.3bc6177b.js"><link rel="prefetch" href="/assets/js/17.49c0c263.js"><link rel="prefetch" href="/assets/js/18.bf4dbf82.js"><link rel="prefetch" href="/assets/js/19.da9a9960.js"><link rel="prefetch" href="/assets/js/2.fbed75fa.js"><link rel="prefetch" href="/assets/js/20.c2e4c734.js"><link rel="prefetch" href="/assets/js/21.3266e6c1.js"><link rel="prefetch" href="/assets/js/23.3ce259aa.js"><link rel="prefetch" href="/assets/js/24.9722cdad.js"><link rel="prefetch" href="/assets/js/25.de7f6c54.js"><link rel="prefetch" href="/assets/js/26.f4f942ff.js"><link rel="prefetch" href="/assets/js/27.459dd7d7.js"><link rel="prefetch" href="/assets/js/28.4d86e4f0.js"><link rel="prefetch" href="/assets/js/29.462e30ba.js"><link rel="prefetch" href="/assets/js/3.7a07be06.js"><link rel="prefetch" href="/assets/js/4.38531193.js"><link rel="prefetch" href="/assets/js/7.8d0a2ec4.js"><link rel="prefetch" href="/assets/js/9.1df726bd.js">
    <link rel="stylesheet" href="/assets/css/0.styles.fa616454.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div><div class="header-wrap" data-v-55a781be><div class="header page" data-v-55a781be><div class="left" data-v-55a781be><div class="motto" data-v-55a781be><div class="line" data-v-55a781be>暮春早夏的月亮</div> <div class="line" data-v-55a781be>原是情人的月亮，不比秋冬是诗人的月亮</div></div> <div class="nav" data-v-55a781be><a href="/" class="nav-item" data-v-55a781be>首页</a><a href="https://github.com/Yidadaa" class="nav-item" data-v-55a781be>Github</a></div></div> <div class="right search" data-v-55a781be><input type="text" placeholder="搜索" class="search-bar" data-v-55a781be></div></div></div> <div class="page post-page"><div class="title"><div class="post-title">经典统计学习方法——决策树(ID3/C4.5/CART)</div></div> <div class="info"><div class="author">Yidadaa</div> <div class="date">2017/08/18</div></div> <div class="post-content"><div class="content__default"><h1 id="经典统计学习方法——决策树-id3-c4-5-cart"><a href="#经典统计学习方法——决策树-id3-c4-5-cart" class="header-anchor">#</a> 经典统计学习方法——决策树(ID3/C4.5/CART)</h1> <p>最近开始技术♂转型，开始搞机器学习，使用教材是李航老师的《统计学习方法》，基本涵盖了经典的机器学习方法，只不过缺少神经网络部分，准备看完这本书之后，继续学习 <a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener noreferrer">CS231n<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> 。</p> <p>前三章的内容都比较基础，第一章介绍了统计学习的基本要素以及基本步骤，第二、三章分别介绍了两种基础的模型：感知机和k近邻法，都比较简单，50行代码就能搞定。</p> <p>从第四章开始，本书的难度开始逐渐拔高，书中出现了越来越多的数学证明，第四章的朴素贝叶斯分类器中，用到了很多概率论的知识，比如极大似然估计、 贝叶斯估计等。如果要深入机器学习原理的话，还是要回归到线性代数和概率论的学习中。</p> <p>本文着重讲第五章的内容——决策树。</p> <h2 id="决策树简述"><a href="#决策树简述" class="header-anchor">#</a> 决策树简述</h2> <p>决策树是本书出现的第一种真正意义上的高可用方法，当然前一章的朴素贝叶斯分类器也算，但从复杂度熵来讲，决策树更胜一筹。</p> <p>决策树是一种基本的分类与回归方法，决策树的学习包括：特征选择、决策树的生成和决策树的修剪。其中特征选择决定了决策树的结构，决策树的生成和修剪阶段主要决定决策树的复杂度（深度）。</p> <h2 id="决策树的特征选择"><a href="#决策树的特征选择" class="header-anchor">#</a> 决策树的特征选择</h2> <p>决策树特征选择方式的不同，衍生出了不同的算法，比如ID3、C4.5、CART等。以这三种为例，其实ID3与C4.5只是特征选择函数不同，前者依照信息增益，后者依照信息增益比，生成的树的结构很相似，同时也使用相同的剪枝算法。CART较为特殊，后文将其分开来讲。</p> <h2 id="id3与c4-5算法"><a href="#id3与c4-5算法" class="header-anchor">#</a> ID3与C4.5算法</h2> <p>决策树生成过程中，通过计算不同特征的划分带来的信息增益，可以决定是否继续生成决策树。</p> <p>这两种算法生成的决策树，每一支子树都是一个特征值的可能值，使用时只需要按照标定的顺序，对输入变量各个特征值沿着树从根节点一直比对，延续到的叶节点就标定了该输入变量的最终分类。</p></div></div> <!----></div> <div class="footer" data-v-c51747ec><div class="footer-content page" data-v-c51747ec>
    Copyright 2020
  </div></div></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.d0804d39.js" defer></script><script src="/assets/js/8.2b72a042.js" defer></script><script src="/assets/js/6.7f8a78fa.js" defer></script><script src="/assets/js/22.7da8e57d.js" defer></script><script src="/assets/js/5.4dfe86e6.js" defer></script>
  </body>
</html>
