(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{101:function(t,c,i){},123:function(t,c,i){"use strict";var s=i(101);i.n(s).a},163:function(t,c,i){"use strict";i.r(c);i(123);var s=i(2),v=Object(s.a)({},(function(){var t=this.$createElement,c=this._self._c||t;return c("div",{staticClass:"cv"},[c("Header"),this._v(" "),this._m(0),this._v(" "),c("Footer")],1)}),[function(){var t=this,c=t.$createElement,i=t._self._c||c;return i("div",{staticClass:"page cv-content"},[i("div",{staticClass:"cv-header cv-two-column cv-section"},[i("div",{staticClass:"cv-info"},[i("div",{staticClass:"cv-author"},[t._v("张义飞")]),t._v(" "),i("div",{staticClass:"cv-contact"},[t._v("电话：+86 13032883129")]),t._v(" "),i("div",{staticClass:"cv-contact"},[t._v("邮箱：flynn.zhang@foxmail.com")]),t._v(" "),i("div",{staticClass:"cv-contact"},[t._v("主页：blog.simplenaive.cn")]),t._v(" "),i("div",{staticClass:"cv-contact"},[t._v("Github：github.com/Yidadaa")])]),t._v(" "),i("div",{staticClass:"cv-sub-info cv-right-column"},[i("div",{staticClass:"cv-research-interest"},[t._v("三维视觉")]),t._v(" "),i("div",{staticClass:"cv-dob"},[t._v("DOB: 1997/01/20")]),t._v(" "),i("div",{staticClass:"cv-city"},[t._v("Chengdu, China")])])]),t._v(" "),i("div",{staticClass:"cv-two-column"},[i("div",{staticClass:"cv-section education cv-left-column"},[i("div",{staticClass:"cv-section-title"},[t._v("教育背景")]),t._v(" "),i("div",{staticClass:"cv-two-column"},[i("div",{staticClass:"cv-left-column cv-school"},[t._v("硕士，电子科技大学")]),t._v(" "),i("div",{staticClass:"cv-right-column cv-time-range"},[t._v("2018.09 - 2021.06")])]),t._v(" "),i("div",{staticClass:"cv-major"},[t._v("计算机科学与工程学院，计算机科学专业")]),t._v(" "),i("div",{staticClass:"cv-two-column"},[i("div",{staticClass:"cv-left-column cv-school"},[t._v("硕士，电子科技大学")]),t._v(" "),i("div",{staticClass:"cv-right-column cv-time-range"},[t._v("2018.09 - 2021.06")])]),t._v(" "),i("div",{staticClass:"cv-major"},[t._v("计算机科学与工程学院，计算机科学专业")])]),t._v(" "),i("div",{staticClass:"cv-section honor cv-right-column"},[i("div",{staticClass:"cv-section-title"},[t._v("荣誉 & 奖项")]),t._v(" "),i("div",{staticClass:"cv-two-column"},[i("div",{staticClass:"cv-left-column cv-honor"},[t._v("研究生二等学业奖学金")]),t._v(" "),i("div",{staticClass:"cv-right-column cv-time-range"},[t._v("2019.10")])]),t._v(" "),i("div",{staticClass:"cv-two-column"},[i("div",{staticClass:"cv-left-column cv-honor"},[t._v("OPPO AI 挑战赛人像分割任务 决赛优秀奖")]),t._v(" "),i("div",{staticClass:"cv-right-column cv-time-range"},[t._v("2019.04")])]),t._v(" "),i("div",{staticClass:"cv-two-column"},[i("div",{staticClass:"cv-left-column cv-honor"},[t._v("研究生一等学业奖学金")]),t._v(" "),i("div",{staticClass:"cv-right-column cv-time-range"},[t._v("2018.10")])])])]),t._v(" "),i("div",{staticClass:"cv-section experience"},[i("div",{staticClass:"cv-section-title"},[t._v("实习 & 研究经历")]),t._v(" "),i("ul",{staticClass:"cv-experience-list"},[i("li",{staticClass:"cv-experience-item"},[i("div",{staticClass:"cv-two-column cv-experience-header"},[i("div",{staticClass:"cv-left-column cv-experience-title"},[t._v("三维视觉中的深度估计算法")]),t._v(" "),i("div",{staticClass:"cv-right-column cv-time-range"},[t._v("from 2019.04")])]),t._v(" "),i("ul",{staticClass:"cv-experience-sub-item"},[i("li",{staticClass:"cv-li"},[t._v("研究⽅向是基于单目视频序列的无监督深度估计算法，基于深度神经⽹络的无监督训练流程可以很快地被迁移到全新环境中，并且训练时只需要单⽬摄像头视频数据，⾮常有应⽤前景。")]),t._v(" "),i("li",{staticClass:"cv-li"},[t._v("当前的想法：现有的无监督训练流程有着收敛过慢的缺点，尝试从以下⼏个⽅⾯改进：Co-attention 模块已被证明可以很好地挖掘相邻视频帧中具有较⾼相似度的特征区域，所以尝试在特征图层⾯对相邻帧的特征进⾏ attention，使得特征相似度较⾼的区域产⽣更相近的深度图；其次⽬前无监督流程中的 PoseNet 的⾃监督信号完全来⾃于与残差图估计⽹络联合建⽴的重建损失，所以提出尝试使⽤ SLAM 系统后端中的滤波⽅法对 PoseNet 的输出做约束，以期提升 PoseNet 的性能。")])])]),t._v(" "),i("li",{staticClass:"cv-experience-item"},[i("div",{staticClass:"cv-two-column cv-experience-header"},[i("div",{staticClass:"cv-left-column cv-experience-title"},[t._v("基于 Unity 虚拟环境和强化学习的机械臂控制算法 @ 毕业设计")]),t._v(" "),i("div",{staticClass:"cv-right-column cv-time-range"},[t._v("2017.10 - 2018.06")])]),t._v(" "),i("ul",{staticClass:"cv-experience-sub-item"},[i("li",{staticClass:"cv-li"},[t._v("强化学习算法在机械智能控制中愈发重要，然而强化学习算法往往需要在训练阶段通过大量地 exploration 与环境交互取得数据来优化策略，这种训练策略将会在真实世界带来极高的时间和物料成本，本文提出了一种架构，可以使得现有强化学习模型可以实时与 Unity 中的虚拟环境交互并获取训练数据，为迁移至真实环境提供预训练基础。")]),t._v(" "),i("li",{staticClass:"cv-li"},[t._v("本文主要工作如下：1) 构建了一个沟通 Unity 运行时和 Python 运行时的中间层，使得基于 Tensorflow 和 Pytorch 的构建的\n\t\t\t\t深度学习模型可以与 Unity 虚拟环境交互；2) 实现了强化学习中经典的 PPO 算法，并分别在二维和三维环境中设计对应的任务来验证算法和中间层的可用性；\n\t\t\t\t3) 基于本文提出的架构，探讨了多线程以及离屏或低分辨率渲染等手段对训练任务的加速能力。")])])])])]),t._v(" "),i("div",{staticClass:"cv-section coding"},[i("div",{staticClass:"cv-section-title"},[t._v("开源项目 & 编程能力")]),t._v(" "),i("div",{staticClass:"cv-coding-item"},[i("div",{staticClass:"cv-two-column"},[i("div",{staticClass:"cv-left-column cv-coding-title"},[i("a",{staticClass:"cv-coding-link",attrs:{href:"https://github.com/Yidadaa/Pytorch-Video-Classification"}},[t._v("github.com/Yidadaa/Pytorch-Video-Classification")]),t._v(" "),i("span",{staticClass:"cv-coding-language"},[t._v("(Python / Pytorch) ~ 500 lines")])]),t._v(" "),i("div",{staticClass:"cv-right-column cv-time-range"},[t._v("2019.04")])]),t._v(" "),i("div",{staticClass:"cv-coding-desc"},[t._v("基于 CNN-RNN 架构的视频动作分类⽹络，在 UCF101 上达到 80% 的准确率。")])]),t._v(" "),i("div",{staticClass:"cv-coding-item"},[i("div",{staticClass:"cv-two-column"},[i("div",{staticClass:"cv-left-column cv-coding-title"},[i("a",{staticClass:"cv-coding-link",attrs:{href:"https://github.com/Yidadaa/Pytorch-Video-Classification"}},[t._v("github.com/Yidadaa/Pytorch-Video-Classification")]),t._v(" "),i("span",{staticClass:"cv-coding-language"},[t._v("(Python / Pytorch) ~ 500 lines")])]),t._v(" "),i("div",{staticClass:"cv-right-column cv-time-range"},[t._v("2019.04")])]),t._v(" "),i("div",{staticClass:"cv-coding-desc"},[t._v("基于 CNN-RNN 架构的视频动作分类⽹络，在 UCF101 上达到 80% 的准确率。")])]),t._v(" "),i("div",{staticClass:"cv-coding-item"},[i("div",{staticClass:"cv-two-column"},[i("div",{staticClass:"cv-left-column cv-coding-title"},[i("a",{staticClass:"cv-coding-link",attrs:{href:"https://github.com/Yidadaa/Pytorch-Video-Classification"}},[t._v("github.com/Yidadaa/Pytorch-Video-Classification")]),t._v(" "),i("span",{staticClass:"cv-coding-language"},[t._v("(Python / Pytorch) ~ 500 lines")])]),t._v(" "),i("div",{staticClass:"cv-right-column cv-time-range"},[t._v("2019.04")])]),t._v(" "),i("div",{staticClass:"cv-coding-desc"},[t._v("基于 CNN-RNN 架构的视频动作分类⽹络，在 UCF101 上达到 80% 的准确率。")])])])])}],!1,null,"4e646bac",null);c.default=v.exports}}]);